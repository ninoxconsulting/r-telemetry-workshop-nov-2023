---
title: "Getting B.C. Open Data with R"
execute: 
  cache: true
knitr:
  opts_chunk:
    message: false
    warning: false
---

The B.C. Government makes a huge amount of open data available, both spatial and 
non-spatial, and documents it in the [B.C. Data Catalogue](https://catalogue.data.gov.bc.ca).

The `{bcdata}` package allows you to interact with the catalogue, and download data,
directly from within R.

:::: { .columns }

::: { .column width=60% }

- **`bcdc_browse()`**
  - Open the catalogue in your default browser
- **`bcdc_search()`**
  - Search records in the catalogue
- **`bcdc_get_record()`**
  - Print a catalogue record
- **`bcdc_get_data()`**
  - Get catalogue data
- **`bcdc_describe_feature()`**
  - Describe the structure (columns and types) of a dataset
- **`bcdc_query_geodata()`**
  - Get & query catalogue geospatial data available through a [Web Service](https://www2.gov.bc.ca/gov/content?id=95D78D544B244F34B89223EF06DF74E)
]

:::

::: { .column width=40%}
![](images/bcdata.png){width="200"}


:::
::::

We are going to use `{bcdata}` to get some data for our telemetry analysis:

1. BEC
2. VRI
3. Forest Cutblocks
4. Lakes and wetlands
5. Streams
6. Roads

```{r}
#| message: false

library(bcdata)
library(sf)
library(dplyr)
library(mapview)
```

## Create an Area of Interest (AOI)

We'll read in the caribou data created in the previous module, and create an 
area of interest (a bounding box) around it, so we can use that to spatially 
subset the covariate data we will be using.

```{r}
scott <- read_sf("clean_data/caribou.gpkg") |> 
  filter(comments == "Scott") |> 
  st_transform(3005)

scott_bbox <- st_bbox(scott)

## Round to nearest 100m outside the box to align with raster grids
scott_bbox["xmin"] <- floor(scott_bbox["xmin"] / 100) * 100
scott_bbox["ymin"] <- floor(scott_bbox["ymin"] / 100) * 100
scott_bbox["xmax"] <- ceiling(scott_bbox["xmax"] / 100) * 100
scott_bbox["ymax"] <- ceiling(scott_bbox["ymax"] / 100) * 100

scott_aoi <- st_as_sfc(scott_bbox)
```

```{r}
#| eval: !expr '!file.exists(file.path("clean_data", "scott_aoi.gpkg"))'
write_sf(scott_aoi, file.path("clean_data", "scott_aoi.gpkg"), append = FALSE)
```

## BEC

```{r bec-1}
bec <- bcdc_query_geodata("f358a53b-ffde-4830-a325-a5a03ff672c3") |>
    filter(INTERSECTS(scott_aoi)) |> 
    collect() |> 
    select(MAP_LABEL)

mapview(bec) + mapview(st_as_sf(scott_aoi))
```

You can see that filtering using the `INTERSECTS()` function does a good job of 
only downloading the features that intersect the AOI, but it doesn't actually
clip them to the AOI. We can do that with `sf::st_intersection()`:

```{r bec-clipped}
bec <- st_intersection(bec, scott_aoi)

mapview(bec)
```


```{r}
#| eval: !expr '!file.exists(file.path("clean_data", "bec.gpkg"))'
write_sf(bec, file.path("clean_data", "bec.gpkg"))
```
 
## VRI

See a list of [VRI codes](https://www2.gov.bc.ca/assets/gov/farming-natural-resources-and-industry/forestry/stewardship/forest-analysis-inventory/data-management/standards/vegcomp_poly_rank1_data_dictionaryv5_2019.pdf).

```{r}
vri <- bcdc_query_geodata("2ebb35d8-c82f-4a17-9c96-612ac3532d55") |> 
  filter(INTERSECTS(scott_aoi)) |> 
  select(PROJ_AGE_CLASS_CD_1,BCLCS_LEVEL_4,CROWN_CLOSURE_CLASS_CD) |>  
  collect() |> 
  st_intersection(scott_aoi)
```

We want to split this into separate files for different variables:

- Coniferous-leading stands
- Stands with age greater than 40 yrs (age class >=3)
- Crown closure

```{r}

# Tree coniferous leading - select coniferous leading vri plots
vri_conif <- vri |>  
    mutate(conif = BCLCS_LEVEL_4) |> 
    filter(conif == "TC") |> 
    select(conif)

#plot(vri_conif$BCLCS_LEVEL_4)
```

```{r}
#| eval: !expr '!file.exists(file.path("clean_data","vri_conif.gpkg"))'
write_sf(vri_conif, file.path("clean_data","vri_conif.gpkg") , append = FALSE)
```

```{r}
# Age class greater than 40 years
vri_ageclass <- vri |> 
    mutate(age_class = as.numeric(PROJ_AGE_CLASS_CD_1)) |> 
    filter(age_class >= 3) |> 
    select(age_class)
```

```{r}
#| eval: !expr '!file.exists(file.path("clean_data", "vri_ageclass.gpkg"))'
write_sf(vri_ageclass, file.path("clean_data", "vri_ageclass.gpkg"), append = FALSE)
```

```{r}
# Crown closure class 
vri_cc <- vri |> 
    mutate(cc_class = as.numeric(CROWN_CLOSURE_CLASS_CD)) |> 
    select(cc_class)
```

```{r}
#| eval: !expr '!file.exists(file.path("clean_data", "vri_cc.gpkg"))'
write_sf(vri_cc, file.path("clean_data", "vri_cc.gpkg"), append = FALSE)
```
 
## Cutblocks

```{r}
cutblocks <- bcdc_query_geodata("b1b647a6-f271-42e0-9cd0-89ec24bce9f7") |>
  filter(
    INTERSECTS(scott_aoi), 
    HARVEST_YEAR >= 1993) |>
  select(HARVEST_YEAR) |>
  collect()
```

```{r}
#| eval: !expr '!file.exists(file.path("clean_data", "cutblocks.gpkg"))'
write_sf(cutblocks, file.path("clean_data", "cutblocks.gpkg"), append = FALSE)
```

## Water bodies

### Searching the catologue for the BC Freshwater Atlas

We can search the catalogue for data using keywords, with `bcdc_search()`. Control
the number of results returned with `n`.

```{r}
bcdc_search("freshwater atlas", n = 20)
```

```{r}

## LAKES ##

# 1 Square Kilometer = 100.00 Hectare

# Uses date filter which filters lakes
lakes <- bcdc_query_geodata("cb1e3aba-d3fe-4de1-a2d4-b8b6650fb1f6") |>
  filter(INTERSECTS(scott_aoi)) |>
  select(id, WATERBODY_TYPE, AREA_HA) |>
  collect() |> 
  select(id, WATERBODY_TYPE, AREA_HA)

# download wetlands

wetlands <- bcdc_query_geodata("93b413d8-1840-4770-9629-641d74bd1cc6") |>
  filter(INTERSECTS(scott_aoi)) |>
  select(id, WATERBODY_TYPE, AREA_HA) |>
  filter(AREA_HA < 100) |>
  collect() |> 
  select(id, WATERBODY_TYPE, AREA_HA)

water <- bind_rows(lakes, wetlands)
```

```{r}
#| eval: !expr '!file.exists(file.path("clean_data", "water.gpkg"))'
write_sf(wetlands, file.path("clean_data", "water.gpkg"), append = FALSE)
```

## stream index

We can get the columns in a given dataset with `bcdc_describe_feature()`:

```{r}
streams_cols <- bcdc_describe_feature("92344413-8035-4c08-b996-65a9b3f62fca")
print(streams_cols, n = 20)
```

Let's use the `STREAM_ORDER` column to just get streams of order 3 and 4
and still intersect with our AOI.

```{r}
streams <- bcdc_query_geodata("92344413-8035-4c08-b996-65a9b3f62fca") |>
  filter(
    INTERSECTS(scott_aoi), 
    STREAM_ORDER >= 3
  ) |>
  select(id, STREAM_ORDER) |>
  collect() |> 
  select(id, STREAM_ORDER) |>
  st_zm()
```

```{r}
#| eval: !expr '!file.exists(file.path("clean_data", "streams.gpkg"))'
write_sf(streams, file.path("clean_data", "streams.gpkg"), append = FALSE)
```

## roads

```{r}
roads <- bcdc_query_geodata("bb060417-b6e6-4548-b837-f9060d94743e") |> 
  filter(INTERSECTS(scott_aoi))  |> 
  select("id", "ROAD_CLASS", "ROAD_SURFACE") |> 
  collect() |> 
  select(ROAD_SURFACE, ROAD_CLASS) |> 
  st_intersection(scott_aoi) |> # clip roads so all inside aoi
  st_cast("MULTILINESTRING")
```

```{r}
#| eval: !expr '!file.exists(file.path("clean_data", "roads.gpkg"))'
write_sf(roads, file.path("clean_data", "roads.gpkg"), append = FALSE)
```
