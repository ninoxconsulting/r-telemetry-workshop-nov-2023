{
  "hash": "ea3d89728a78e311e76e1a9366218e5c",
  "result": {
    "markdown": "---\ntitle: \"Introduction to Telemetry Data\"\nexecute: \n  cache: true\nparams:\n  write: true\n---\n\n\n## How to QA and summarize telemetry data\n\n## Overview:\n\nIn this module we will read in, clean, QA and summarize raw telemetry data. This includes:\n\n-   read in data as csv/xlsx and convert to spatial data\n\n-   QA data for missing values and poor coordinate precision\n\n-   generate tabular summaries\n\n-   standardize fix rate of telemetry points for future analysis\n\n## Background data:\n\nIn this workshop we will use GPS telemetry data from Mountain Caribou (*Rangifer terendus*) herds in the Peace region of British Columbia. The full data set and metadata can be found on [movebank](https://www.movebank.org/cms/webapp?gwt_fragment=page=studies,path=study216040785), also see [bonus content - How to download data from movebank](bonus-movebank.qmd). The data set used in this course has been modified for demonstration purposes and should not be used in analysis.\n\n### 1. Reading data into R.\n\nIn this course we will be providing two files (Mountain caribou in British Columbia-reference-data.csv and Mountain caribou.xlsx). The first task is to look at the data to make sense of what we have.\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/read-in-raw-data_672cea378d62e00cba702d82233c42cf'}\n\n```{.r .cell-code}\n# load libraries \n\nlibrary(readr)\nlibrary(sf)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(ggplot2)\n\n\n# Read in data files.\n\nref_raw <- read_csv(\"raw_data/Mountain caribou in British Columbia-reference-data.csv\", \n                    name_repair = \"universal\") # use this to standardise the column names\n\nloc_raw <- read_xlsx(\"raw_data/Mountain caribou.xlsx\")\n```\n:::\n\n\nLets take a look....\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/review-raw-data_5e82e96d7bffafee3bf562718eba44bc'}\n\n```{.r .cell-code}\n# Reference data \n\nhead(ref_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 26\n  tag.id  animal.id  animal.taxon      deploy.on.date deploy.off.date\n  <chr>   <chr>      <chr>             <time>         <time>         \n1 151.51  HR_151.510 Rangifer tarandus    NA             NA          \n2 C04a    GR_C04     Rangifer tarandus    NA          59:00          \n3 C03     GR_C03     Rangifer tarandus    NA             NA          \n4 151.805 HR_151.805 Rangifer tarandus    NA             NA          \n5 151.76  HR_151.760 Rangifer tarandus    NA             NA          \n6 151.72  HR_151.720 Rangifer tarandus    NA             NA          \n# ℹ 21 more variables: animal.death.comments <chr>, animal.life.stage <chr>,\n#   animal.reproductive.condition <chr>, animal.sex <chr>,\n#   animal.taxon.detail <chr>, attachment.type <chr>,\n#   deploy.off.latitude <dbl>, deploy.off.longitude <dbl>,\n#   deploy.on.latitude <dbl>, deploy.on.longitude <dbl>,\n#   deploy.on.person <chr>, deployment.comments <chr>,\n#   deployment.end.comments <chr>, deployment.end.type <chr>, …\n```\n:::\n\n```{.r .cell-code}\nnames(ref_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"tag.id\"                        \"animal.id\"                    \n [3] \"animal.taxon\"                  \"deploy.on.date\"               \n [5] \"deploy.off.date\"               \"animal.death.comments\"        \n [7] \"animal.life.stage\"             \"animal.reproductive.condition\"\n [9] \"animal.sex\"                    \"animal.taxon.detail\"          \n[11] \"attachment.type\"               \"deploy.off.latitude\"          \n[13] \"deploy.off.longitude\"          \"deploy.on.latitude\"           \n[15] \"deploy.on.longitude\"           \"deploy.on.person\"             \n[17] \"deployment.comments\"           \"deployment.end.comments\"      \n[19] \"deployment.end.type\"           \"deployment.id\"                \n[21] \"manipulation.type\"             \"study.site\"                   \n[23] \"tag.beacon.frequency\"          \"tag.manufacturer.name\"        \n[25] \"tag.model\"                     \"tag.serial.no\"                \n```\n:::\n\n```{.r .cell-code}\nref_short <- ref_raw |> \n  select(tag.id, animal.id, deploy.on.date, animal.sex, animal.reproductive.condition,\n         deployment.end.type,tag.model, tag.manufacturer.name, tag.serial.no)\n\n# Location data\n\nhead(loc_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 14\n    event.id timestamp location.long location.lat   DOP FixType     herd \n       <dbl> <chr>             <dbl>        <dbl> <dbl> <chr>       <chr>\n1 2270202009 01:00.0           -124.         55.9     1 val. GPS-3D Scott\n2 2270202041 01:00.0           -124.         55.9     1 val. GPS-3D Scott\n3 2270202100 01:00.0           -124.         55.9     1 val. GPS-3D Scott\n4 2270202901 01:00.0           -123.         55.8     1 val. GPS-3D Scott\n5 2270202132 01:00.0           -123.         55.9     1 val. GPS-3D Scott\n6 2270202890 01:00.0           -123.         55.9     1 val. GPS-3D Scott\n# ℹ 7 more variables: study.specific.measurement <chr>, sensor.type <chr>,\n#   individual.taxon.canonical.name <chr>, tag.local.identifier <chr>,\n#   individual.local.identifier <chr>, study.name <chr>, date <chr>\n```\n:::\n:::\n\n\nWe can combine these data sets and keep the columns of interest\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/filter-raw-fields_7834d4bcb41eb2985e772d85c4794a74'}\n\n```{.r .cell-code}\n# create a new data set by joining on a common field\n\nall_data <- left_join(loc_raw, ref_raw, by = c('tag.local.identifier' = 'tag.id') )\n\n# filter the columns of interest\n\nall_data <- all_data |> \n  select(event.id, location.long, location.lat, DOP, FixType, herd,\n         study.specific.measurement, sensor.type, tag.local.identifier, date, animal.id,\n         animal.sex, animal.reproductive.condition, tag.manufacturer.name, tag.model )\n```\n:::\n\n\n### 2. Clean and QA the data\n\n#### 2a. Data input errors and column formats\n\nLets check for NA or missing values.\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/remove-NA-values_189850773b355b47501ca44d5cafe27b'}\n\n```{.r .cell-code}\nhead(all_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 15\n  event.id location.long location.lat   DOP FixType herd  study.specific.measu…¹\n     <dbl>         <dbl>        <dbl> <dbl> <chr>   <chr> <chr>                 \n1   2.27e9         -124.         55.9     1 val. G… Scott Summer                \n2   2.27e9         -124.         55.9     1 val. G… Scott Summer                \n3   2.27e9         -124.         55.9     1 val. G… Scott Summer                \n4   2.27e9         -123.         55.8     1 val. G… Scott Summer                \n5   2.27e9         -123.         55.9     1 val. G… Scott Winter                \n6   2.27e9         -123.         55.9     1 val. G… Scott Summer                \n# ℹ abbreviated name: ¹​study.specific.measurement\n# ℹ 8 more variables: sensor.type <chr>, tag.local.identifier <chr>,\n#   date <chr>, animal.id <chr>, animal.sex <chr>,\n#   animal.reproductive.condition <chr>, tag.manufacturer.name <chr>,\n#   tag.model <chr>\n```\n:::\n\n```{.r .cell-code}\n# check if there are NA's in the data \n\napply(all_data, 2, function(x) any(is.na(x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                     event.id                 location.long \n                        FALSE                          TRUE \n                 location.lat                           DOP \n                         TRUE                         FALSE \n                      FixType                          herd \n                        FALSE                          TRUE \n   study.specific.measurement                   sensor.type \n                         TRUE                         FALSE \n         tag.local.identifier                          date \n                        FALSE                         FALSE \n                    animal.id                    animal.sex \n                        FALSE                         FALSE \nanimal.reproductive.condition         tag.manufacturer.name \n                         TRUE                         FALSE \n                    tag.model \n                        FALSE \n```\n:::\n:::\n\n\nSeveral columns contain NA's and need more exploration.\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/remove-NA-values2_8d00c43d058ab49d9b159055c5d8f200'}\n\n```{.r .cell-code}\n# filter missing values for latitude, longitude and date.\n\ntdata <- all_data |> \n  filter(!is.na(date)) |> # keep any rows which are not NA\n  filter(!is.na(location.long)) |> \n  filter(!is.na(location.lat))\n\n\n# Herd\nunique(tdata$herd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Scott\"      \"Burnt Pine\" NA          \n```\n:::\n\n```{.r .cell-code}\n# two missing herd values which we can fill in (or delete)\n\ntdata <- tdata |> \n  mutate(herd = case_when(\n    animal.id == \"BP_car043\" ~ \"Burnt Pine\", \n    animal.id == \"SC_car170\" ~ \"Scott\",\n    .default = herd\n  ))\n\n\n## rerun the NA check to confirm \n\n# apply(tdata, 2, function(x) any(is.na(x)))\n```\n:::\n\n\n#### 2b. Dealing with date-times\n\nTimestamps can be confusing and problematic, especially when working with multiple programs and file types. One solution is to split the date into separate components (year, month, day, time).\n\nWe firstly need to format the raw data into a date format using **lubridate** package.\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/convert-time-stamp_d12121617919b118307d9800aa345503'}\n\n```{.r .cell-code}\n# calculate time differences\ntdata <- tdata  |> \n  mutate(date_time = ymd_hms(date)) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `date_time = ymd_hms(date)`.\nCaused by warning:\n!  5 failed to parse.\n```\n:::\n\n```{.r .cell-code}\n# owch we still have an error in this dataset\n\n# lets see if we can find it..... \n\nhead(sort(unique(tdata$date)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2003-12-12 13:03:29.000\" \"2003-12-13 09:03:10.000\"\n[3] \"2003-12-14 05:03:11.000\" \"2003-12-15 01:03:10.000\"\n[5] \"2003-12-15 21:04:00.000\" \"2003-12-16 17:03:10.000\"\n```\n:::\n\n```{.r .cell-code}\ntail(sort(unique(tdata$date)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2016-03-16 10:01:00.000\" \"2016-03-16 17:49:00.000\"\n[3] \"2016-03-16 19:49:00.000\" \"2016-03-17 17:53:00.000\"\n[5] \"2016-03-17 19:53:00.000\" \"NA\"                     \n```\n:::\n\n```{.r .cell-code}\n# Note this is not the same format as an NA we searched for above. i.e. \"NA\" is not equal to NA. \n\n# lets remove the NA \n\ntdata <- tdata  |> \n  filter(date != \"NA\")\n\n# re-run the code to convert to a date format. \n\ntdata  <- tdata  |> \n  mutate(date_time = ymd_hms(date)) \n\n# lets take a look \n\nhead(tdata$date_time) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2013-09-23 10:01:00 UTC\" \"2013-10-09 10:01:00 UTC\"\n[3] \"2013-10-30 10:01:00 UTC\" \"2014-08-11 10:01:00 UTC\"\n[5] \"2013-11-10 02:01:00 UTC\" \"2014-08-07 10:01:00 UTC\"\n```\n:::\n\n```{.r .cell-code}\n# Note the Universal Coordinated Time Zone\n\n\n# lets split this data format into something more useful \n\ntdata  <- tdata  |> \n  mutate(year = year(date_time )) |> \n  mutate(month = month(date_time ),\n         day = day(date_time),\n         hour = hour(date_time),\n         minute = minute(date_time))\n```\n:::\n\n\n#### 2c. Spatial accuracy QA.\n\nNext we will review the spatial accuracy of the point data. We have two columns which contain accuracy metrics: DOP (Dilution of Precision), and Fix Type.\n\nNote: For quick review of spatial errors it is helpful to view the data in QGIS or built a quick map or vizualisation (this is covered later in the [workshop](04-spatial-data-viz.qmd)).\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/clean-lat-longs_25e6237db94e9747b4fca5b515410af7'}\n\n```{.r .cell-code}\n# review Latitudes and Longitude values \n\nrange(tdata$location.lat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  55.2249 155.4764\n```\n:::\n\n```{.r .cell-code}\nhist(tdata$location.lat)\n```\n\n::: {.cell-output-display}\n![](03-intro-telemetry-data_files/figure-html/clean-lat-longs-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Note some points are above 65 Latitude\n\nrange(tdata$location.long)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -123.6684  -22.0000\n```\n:::\n\n```{.r .cell-code}\nhist(tdata$location.long)\n```\n\n::: {.cell-output-display}\n![](03-intro-telemetry-data_files/figure-html/clean-lat-longs-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Lets set an upper limit and filter values which are within the range we want.\n\ntdata <- tdata |> \n  filter(location.long <= -100) |> \n  filter(location.lat <= 65)\n```\n:::\n\n\n#### 2d. Spatial Precision QA.\n\nTo refine the level of precision we can use the metrics DOP (Dilution of Precision) and Fixtype information which is associated with each location observation.\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/DOP-review_45f9d81d1d4dcfc7580a963fe6f9ff53'}\n\n```{.r .cell-code}\nrange (tdata$DOP)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  1.0 43.1\n```\n:::\n\n```{.r .cell-code}\nhist(tdata$DOP)\n```\n\n::: {.cell-output-display}\n![](03-intro-telemetry-data_files/figure-html/DOP-review-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#unique(tdata$DOP)\n\n# We only want to keep fixes with a DOP less than 10m\n\nfdata <- tdata |> \n  filter(DOP <= 10)\n```\n:::\n\n\nThe Fixtype is generally classified into categories, based on the level of precision of the calculated location i.e. the number of satellite used to triangulate the fixes. These metrics will vary with the device type and model. More information will be available through the manufacturer website (For example: [Lotek Iridium collars](https://www.lotek.com/products/litetrack-iridium-250-750) ).\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/fixtype-review_99bf864b8225d0791c57654623c31f59'}\n\n```{.r .cell-code}\n# check the number of records per fix type\n\nfdata |> \n  group_by(FixType) |> \n  summarise(count = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  FixType     count\n  <chr>       <int>\n1 GPS-2D         92\n2 GPS-3D        291\n3 val. GPS-3D 16801\n```\n:::\n\n```{.r .cell-code}\n# We will only keep the higher level of precision\n\nfdata <- fdata |> \n  filter(FixType != \"GPS-2D\")\n\n# see what the data looks like\nglimpse(fdata)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 17,092\nColumns: 21\n$ event.id                      <dbl> 2270202009, 2270202041, 2270202100, 2270…\n$ location.long                 <dbl> -123.6036, -123.5987, -123.5903, -123.49…\n$ location.lat                  <dbl> 55.90000, 55.87343, 55.87470, 55.83741, …\n$ DOP                           <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ FixType                       <chr> \"val. GPS-3D\", \"val. GPS-3D\", \"val. GPS-…\n$ herd                          <chr> \"Scott\", \"Scott\", \"Scott\", \"Scott\", \"Sco…\n$ study.specific.measurement    <chr> \"Summer\", \"Summer\", \"Summer\", \"Summer\", …\n$ sensor.type                   <chr> \"gps\", \"gps\", \"gps\", \"gps\", \"gps\", \"gps\"…\n$ tag.local.identifier          <chr> \"car170\", \"car170\", \"car170\", \"car170\", …\n$ date                          <chr> \"2013-09-23 10:01:00.000\", \"2013-10-09 1…\n$ animal.id                     <chr> \"SC_car170\", \"SC_car170\", \"SC_car170\", \"…\n$ animal.sex                    <chr> \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", …\n$ animal.reproductive.condition <chr> \"with calf: N\", \"with calf: N\", \"with ca…\n$ tag.manufacturer.name         <chr> \"ATS\", \"ATS\", \"ATS\", \"ATS\", \"ATS\", \"ATS\"…\n$ tag.model                     <chr> \"GPS Iridium\", \"GPS Iridium\", \"GPS Iridi…\n$ date_time                     <dttm> 2013-09-23 10:01:00, 2013-10-09 10:01:0…\n$ year                          <dbl> 2013, 2013, 2013, 2014, 2013, 2014, 2014…\n$ month                         <dbl> 9, 10, 10, 8, 11, 8, 9, 12, 7, 11, 6, 12…\n$ day                           <int> 23, 9, 30, 11, 10, 7, 19, 6, 8, 24, 20, …\n$ hour                          <int> 10, 10, 10, 10, 2, 10, 2, 18, 18, 2, 2, …\n$ minute                        <int> 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 0, 0, 1…\n```\n:::\n\n```{.r .cell-code}\n# lets check if this column is any use? \n# unique(fdata$sensor.type)\n```\n:::\n\n\nThe final step is to remove redundant columns.\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/remove-unused-cols_d367f15ee7ae2de18c425f668e6a632e'}\n\n```{.r .cell-code}\nfdata <- fdata |> \n  select(-FixType, -DOP, -date, -study.specific.measurement, -sensor.type, -event.id)\n```\n:::\n\n\n### 3. Export cleaned data\n\n#### 3a. Export as a table\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/write-csv_d57748dd3c5bfa4084ba7b59afcb756a'}\n\n```{.r .cell-code}\nwrite_csv(fdata, \"clean_data/caribou.csv\")\n```\n:::\n\n\n#### 3b. Convert to spatial file and export\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/write-out_e207a13208ef16a79a266a8250f23b40'}\n\n```{.r .cell-code}\n# convert to a sf object and transform to BC Albers\n\nbou <- st_as_sf(fdata, coords = c(\"location.long\", \"location.lat\"), \n                crs = 4326, remove = FALSE) |> \n  st_transform(3005)\n```\n:::\n\n\nexport as .gpkg\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/unnamed-chunk-1_834185486cb322a3b2cd41ee238eb697'}\n\n```{.r .cell-code}\nwrite_sf(bou, \"clean_data/caribou.gpkg\")\n```\n:::\n\n\nWe can also export to a .shp file\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/unnamed-chunk-2_94da9c28b52bdf377f41792c37c9f916'}\n\n```{.r .cell-code}\nwrite_sf(bou, \"clean_data/caribou.shp\")\n\n# note warning on names for shapefile\n```\n:::\n\n\n### 4. Generating tabular summaries\n\nNow we have clean data to work with we can get to the fun data exploration part!\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/read-in-geopackage_98be5dd0d2497c9772a2dd4f6067ec53'}\n\n```{.r .cell-code}\n#bou = read.csv(\"clean_data/caribou.csv\")\n\n# or \n\nbou_sf = read_sf(\"clean_data/caribou.gpkg\")\n\nbou <- st_drop_geometry(bou_sf)\n\nglimpse(bou)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 17,092\nColumns: 15\n$ location.long                 <dbl> -123.6036, -123.5987, -123.5903, -123.49…\n$ location.lat                  <dbl> 55.90000, 55.87343, 55.87470, 55.83741, …\n$ herd                          <chr> \"Scott\", \"Scott\", \"Scott\", \"Scott\", \"Sco…\n$ tag.local.identifier          <chr> \"car170\", \"car170\", \"car170\", \"car170\", …\n$ animal.id                     <chr> \"SC_car170\", \"SC_car170\", \"SC_car170\", \"…\n$ animal.sex                    <chr> \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", …\n$ animal.reproductive.condition <chr> \"with calf: N\", \"with calf: N\", \"with ca…\n$ tag.manufacturer.name         <chr> \"ATS\", \"ATS\", \"ATS\", \"ATS\", \"ATS\", \"ATS\"…\n$ tag.model                     <chr> \"GPS Iridium\", \"GPS Iridium\", \"GPS Iridi…\n$ date_time                     <dttm> 2013-09-23 03:01:00, 2013-10-09 03:01:0…\n$ year                          <dbl> 2013, 2013, 2013, 2014, 2013, 2014, 2014…\n$ month                         <dbl> 9, 10, 10, 8, 11, 8, 9, 12, 7, 11, 6, 12…\n$ day                           <int> 23, 9, 30, 11, 10, 7, 19, 6, 8, 24, 20, …\n$ hour                          <int> 10, 10, 10, 10, 2, 10, 2, 18, 18, 2, 2, …\n$ minute                        <int> 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 0, 0, 1…\n```\n:::\n:::\n\n\n### Many questions we can ask here:\n\n-   how many herds do we have?\n-   how many animals in each herd?\n-   what is the sex ratio of collared animals?\n-   what is the duration of each collar? Start and end years?\n\nLets start with the basics:\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/summarise-clean-data_ac95f2e520c0cb4500c9e7da47e18882'}\n\n```{.r .cell-code}\n# how many herds?\nno_herds = unique(bou$herd)\n\n#How many records per herd ?\nno_records <- bou |> \n  group_by(herd) |> \n  summarise(count = n())\n\n# number of animal records per herd?\nno_animals_id <- bou |> \n  group_by(herd, animal.id) |> \n  summarise(count = n())\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'herd'. You can override using the\n`.groups` argument.\n```\n:::\n\n```{.r .cell-code}\n# animals by sex by herd ?\nno_animals_sex <- bou |> \n  group_by(herd, animal.sex) |> \n  summarise(count = n())\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'herd'. You can override using the\n`.groups` argument.\n```\n:::\n\n```{.r .cell-code}\n# type of collar by herd by collar model?\ncollar_type <- bou |> \n  group_by(herd, tag.manufacturer.name, tag.model) |> \n  summarise(count = n())\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'herd', 'tag.manufacturer.name'. You can\noverride using the `.groups` argument.\n```\n:::\n:::\n\n\nThere is lots of data here, so to make it easy we will just use the Scott herd.\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/summarise-scott-herd_85c9d8cae99f77ba0ae863024f2f3c33'}\n\n```{.r .cell-code}\n# Filter the Scott herd only \n\nsbou <- bou |> \n  filter(herd == \"Scott\")\n\n# tidy the data by removing columns that are redundant\nsbou <- sbou |> select(-herd, -tag.local.identifier, -tag.manufacturer.name, -tag.model)\n\n# how many animals?\nno_sbou <- unique(sbou$animal.id)\n```\n:::\n\n\n#### Question: What is the spread of fixes per season?\n\nNext we format the date variable so we can filter by months and years. We can also assign fixes to seasons based on the following dates :\n\n-   Spring/calving (April,May)\n-   Summer (June to August)\n-   Fall (September to November)\n-   Winter (December to March)\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/add-seasons_cfa905fa03fb8c2b2eddfb9b1c211cef'}\n\n```{.r .cell-code}\nsbou <- sbou |> \n  mutate(season = case_when(\n            month %in% c(4,5) ~ \"spring\",\n            month %in% c(6,7,8) ~ \"summer\",\n            month %in% c(9,10,11) ~ \"fall\",\n            month %in% c(12,1,2,3) ~ \"winter\")) \n            \n  \n# check data spread\ncounts.per.season = sbou |> \n  group_by(season, animal.id) |> \n  summarise(count = n())\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'season'. You can override using the\n`.groups` argument.\n```\n:::\n\n```{.r .cell-code}\nggplot(counts.per.season, aes(x = season, y = count)) + \n  geom_bar(stat = \"identity\") + \n  facet_wrap(~animal.id) +\n  labs(x = \"season\", y = \"no.of.fixes\", title = \"Scott Herd\")\n```\n\n::: {.cell-output-display}\n![](03-intro-telemetry-data_files/figure-html/add-seasons-1.png){width=672}\n:::\n:::\n\n\nThen we can save our plot\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/unnamed-chunk-3_42213f0c59e291260cafd5120167744e'}\n\n```{.r .cell-code}\nggsave(\"caribou_fixes_per_id.jpeg\", width = 10, height = 10, units = \"cm\")\n```\n:::\n\n\n#### Question: What is the duration of the collar data ?\n\nThe duration of the collars is also an important question. These can tell us not only the first and last fix, but also point to potential errors or issues we need to consider for future analysis.\n\nLets calculate the minimum, maximum and duration between fix times.\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/collar-duration_6e143ee9e11ed93698122abb0516e3b3'}\n\n```{.r .cell-code}\n# which years were the collars active?\nggplot(sbou, aes(year, fill = animal.id)) +\n  geom_bar(position = \"dodge\")\n```\n\n::: {.cell-output-display}\n![](03-intro-telemetry-data_files/figure-html/collar-duration-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# calculate the minimum and max dates per collar \n\ntable_max <- sbou |> \n  select(animal.id, date_time) |> # select the columns of interest\n  slice_max(date_time, by = animal.id)  # select the max value of date_time, per animal.id\ncolnames(table_max)<- c(\"animal.id\",\"max\")\n\ntable_min <- sbou |> \n  select(animal.id, date_time) |> \n  slice_min(date_time, by = animal.id) \n\ncolnames(table_min)<- c(\"animal.id\",\"min\")\n\n\n# merge the two tables together and calculate the duration \n\ndur <- left_join(table_max, table_min, by = join_by(animal.id)) |> \n  distinct() |> \n  mutate(duration = max - min) |> # calculate duration (default is days)\n  mutate(dur_days = round( duration, 1)) |> # format the duration \n  mutate(dur_hrs = round(as.numeric(dur_days)*24,1)) |> # convert to hours\n  mutate(year_start = year(min), \n         year_end = year(max))\n\n\n# plot total duration of collar data \n\nggplot(dur, aes(y=factor(animal.id))) +\n  geom_segment(aes(x=min, xend=max, y=factor(animal.id), yend=factor(animal.id)), linewidth = 3)+\n  xlab(\"Date\") + ylab(\"Tag\") \n```\n\n::: {.cell-output-display}\n![](03-intro-telemetry-data_files/figure-html/collar-duration-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(sbou, aes(factor(month), fill = factor(year)))+\n  geom_bar(position = \"dodge\") +\n  facet_wrap(~animal.id)+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```\n\n::: {.cell-output-display}\n![](03-intro-telemetry-data_files/figure-html/collar-duration-3.png){width=672}\n:::\n:::\n\n\n### 5. Standardize fix interval times\n\nAnother data processing method we might need to consider is having a standard density or fix rate for all animals. This may not be required, depending on the research question being asked, but it is useful to assess measures of density.\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/check-fix-per-day_3e79f5cb2fbf0b8c50e94ebb71fea221'}\n\n```{.r .cell-code}\nsbou <- sbou |> \n  arrange(animal.id, date_time)\n\nsbou_dur <- sbou |> \n    mutate(time = as.POSIXct(date_time, format = \"%y/%d/%m %H:%M:%S\")) |> \n    group_by(animal.id) |> \n    mutate(diff = difftime(time, lag(time),  units = c(\"hours\")), \n           diff = as.numeric(diff))\n\n\n# we can see a big range in the time intervals for the fixes\nrange(sbou_dur$diff, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]   0.01666667 111.75000000\n```\n:::\n\n```{.r .cell-code}\n# most fall in the less than than 10 \nhist(sbou_dur$diff)\n```\n\n::: {.cell-output-display}\n![](03-intro-telemetry-data_files/figure-html/check-fix-per-day-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# lets look at the individual animals\nggplot(sbou_dur, aes(diff)) + \n  geom_histogram(bins=30) +\n  facet_grid(.~animal.id)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 4 rows containing non-finite values (`stat_bin()`).\n```\n:::\n\n::: {.cell-output-display}\n![](03-intro-telemetry-data_files/figure-html/check-fix-per-day-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# much of the problem is with the SC_car171 individual \nggplot(sbou_dur, aes(y = diff, x = date_time)) + \n  geom_point() +\n  facet_wrap(.~animal.id, scales = \"free\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 4 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](03-intro-telemetry-data_files/figure-html/check-fix-per-day-3.png){width=672}\n:::\n:::\n\n\nThe number of fixes are relatively steady throughout the years for all individuals except SC_car171? Something looks strange here as there are large spikes in October 2015 and February 2016. Potential mortality signals?\n\nTo create a standardized fix per day, lets take the first fix per day. This could be based on a number of factors, depending on our research question we want to ask. We can use Julian date to filter all fixes.\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/unnamed-chunk-4_fe52e19353c2cd9ebc3d024704e9b575'}\n\n```{.r .cell-code}\n# we can subset base on a Julian date\nsbou_dur <- sbou_dur |> \n  mutate(\n    date2=as.Date(date_time, format = '%Y-%m-%d'), # convert to date type\n    jdate=julian(date2)               # create new column and calculate Julian date \n  )\n\n\n# Check the multiple counts of animals per day \ncounts.per.day.jdate <- sbou_dur |> \n  group_by(animal.id, jdate, year) |> \n  summarise(total = n(), unique = unique(jdate)) |> \n  group_by(animal.id, total, year) |> \n  summarise(total.j = n()) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'animal.id', 'jdate'. You can override\nusing the `.groups` argument.\n`summarise()` has grouped output by 'animal.id', 'total'. You can override\nusing the `.groups` argument.\n```\n:::\n\n```{.r .cell-code}\n# lets plot this data to make more sense of what is happening\nggplot(counts.per.day.jdate, aes(x = total, y = total.j)) + \n  geom_point() +\n  geom_vline(xintercept = 1, color = \"red\")+\n  facet_wrap(.~animal.id + year)\n```\n\n::: {.cell-output-display}\n![](03-intro-telemetry-data_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# lets select the first fix per day \nsbou_sub <- sbou_dur |> \n    group_by(animal.id, jdate) |> \n    slice_sample( n = 1) \n```\n:::\n\n\nWe can write out the standardized fix rate file for future use in analysis.\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/write-standard-subset-csv_2a30695b8c4e0cdc32c1fa57229015d2'}\n\n```{.r .cell-code}\n# lets write this out as .csv and .Gpkg\n\nwrite_csv(sbou_sub, \"clean_data/scott_herd_subset.csv\")\n```\n:::\n\n\nAlternatively we can convert to a sf object and export. Note this is required as we previously remove the spatial components to undertake the summaries above.\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/write-standard-subset-gpk_f9ee4fea4a3384876e3b3f684731a15f'}\n\n```{.r .cell-code}\nsbou_sub_sf <- st_as_sf(sbou_sub, coords = c(\"location.long\", \"location.lat\"), crs = 4326, remove = FALSE) |> \n  st_transform(3005)\n```\n:::\n\n\nExport as .gpkg\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/unnamed-chunk-5_42f74571853b33f1e740c0a2193d8dc4'}\n\n```{.r .cell-code}\n# # export as .gpkg\nwrite_sf(sbou_sub_sf, \"clean_data/scott_herd_subset.gpkg\")\n```\n:::\n\n\n### Add Questions: STILL TO DO:\n\n::: {.callout-tip collapse=\"true\" appearance=\"minimal\"}\n## Your Turn\n\nThe answer is:\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/unnamed-chunk-6_a039e05906524d7f195ea17b5cc2d87e'}\n\n```{.r .cell-code}\n1 + 1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2\n```\n:::\n:::\n\n:::\n\n\n::: {.cell hash='03-intro-telemetry-data_cache/html/unnamed-chunk-7_44f0f6ce255542954fdc2b4a91e40e62'}\n\n```{.r .cell-code}\n# plot months of the year. \nggplot(sbou, aes(factor(month), fill = factor(year)))+\n  geom_bar(position = \"dodge\") +\n  facet_wrap(~animal.id)+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n```\n\n::: {.cell-output-display}\n![](03-intro-telemetry-data_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}